# the update allele frequencies function

# the function should contain three inputs: a string D_file, a string D_file_format, the string ancestry_file, a
# string ancestry_file_format, an integer K and an integer obs;
# the function will provide us an array: updateAF

# D_file: the file location of the Dataframe D, which should be in the same format as following;
#   CHR  RSID       bP       A1 A2  ref_eur_1000G ...  ref_iam_1000G   obs_afr    obs_amr_gnomad    obs_oth_gnomad
#   1    rs2887286  1156131  C  T   0.173275495   ...  0.7093          0.4886100  0.52594300        0.22970500
#   1    rs41477744 2329564  A  G   0.001237745   ...  0.0000          0.0459137  0.00117925        0.00827206
#   1    rs9661525  2952840  G  T   0.168316089   ...  0.2442          0.1359770  0.28605200        0.15561700
#   1    rs2817174  3044181  C  T   0.428212624   ...  0.5000          0.8548790  0.48818000        0.47042500
#   1    rs12139206 3504073  T  C   0.204214851   ...  0.3372          0.7241780  0.29550800        0.25874800
#   1    rs7514979  3654595  T  C   0.004950604   ...  0.0000          0.3362490  0.01650940        0.02481620
# ...
# The dataframe D should contain the CHR, RSID, bP, A1, A2, the reference ancestries and observation ancestries, and
# the order of those columns should also be the same as the example one

# D_file_format: this function can deal with two different data input format, if the data format is tab-delimited text
# the we need to make the file_format as 'tab' to get the dataframe D from a file of such format, which is the common
# used data format when dealing with allel frequencies; if the user only gets the csv data, then the user should input
# file_format as csv. The default is 'tab'.

# ancestry_file: the file location of Dataframe ancestry. For this input, user needs to provide the pi_hat and pi_star
# value for the reference ancestries and observed ancestries they want to estimate. But the function will also provide
# user the option of leaving pi_hat blank, by doing so, the function will call the HA function to get the value of
# pi_hat but in that case, the user needs to provide an additional input K to run the HA function.
# If the user will provide both pi_hat and pi_star, the input should be in the same format as following:

# pi       ref_eur_1000G  obs_afr_gnmoad
# pi_star  0              1
# pi_hat   0.15           0.85

# In this example, we only have one reference ancestry, which is ref_eur_1000G and we have one observed ancestry,
# which is obs_afr_gnomad.
# * One essential thing for the column name of the ancestry: the column names of the reference ancestries and
# observed ancestry should be exactly the same as the one in the dataframe D.

# ancestry_file_format: the data format of the input file of dataframe ancestry(the function of this input is exactly
# the same as the D_file_format. The default is also "tab".

# Integer K; the number of reference ancestries the user inputs
# in the example case, we input 5 reference ancestries: ref_eur_1000G, ref_afr_1000G, ref_sas_1000G, ref_eas_1000G,
# ref_iam_1000G, which stand for European, African, South Asian, East Asian, Indigenous American ancestries,
# respectively.
# The default is none. The user needs to input K only if the user wants to use the Hidden Ancestries Function to get
# the pi_hat,

# Integer obs: when using Hidden Ancestries Function to get pi_hat, the user also needs to input obs to locate the
# observe ancestries we want to work on. It selects the ancestry which is k column(s) after the last reference
# ancestry.
# In the example case, when inputing obs = 1, we work on obs_amr_gnomad and when inputing obs = 2, we will work on
# obs_oth_gnomad.

# Then we get one output updateAF, which is the updated hidden proportions of every reference ancestry we select.

# Example:
# The case that the user inputs both pi_star and pi_hat.
# output = updateHA("D_file_location","D_file_format","ancestry_file_location","ancestry_file_format")
# When the user needs to use the Hidden Ancestries Function to help the user calculate pi_hat, then use command
# output = updateHA("D_file_location","D_file_format","ancestry_file_location","ancestry_file_format", k, obs)

# The output of Example;
#     CHR        RSID        bP  ... obs_amr_gnomad obs_oth_gnomad  updateAF
#       1   rs2887286   1156131  ...       0.525943       0.229705  0.539310
#       1  rs41477744   2329564  ...       0.001179       0.008272  0.051583
#       1   rs9661525   2952840  ...       0.286052       0.155617  0.133343
#       1   rs2817174   3044181  ...       0.488180       0.470425  0.910666
#       1  rs12139206   3504073  ...       0.295508       0.258748  0.793055
#       1   rs7514979   3654595  ...       0.016509       0.024816  0.378376
# ...

import numpy as np
import pandas as pd
import timeit

def updateHA(D_file=None, D_file_format='tab', ancestry_file=None, ancestry_file_format='tab', k=None, obs=1,x_guess=None):
    # Start the clock
    start = timeit.default_timer()

    # Check the input formt of D_file_format
    if D_file_format not in ['tab','csv']:
        print('Please ensure the data format of D is either tab-delimited txt or csv')

    # Check the input formt of ancestry_file_format
    if ancestry_file_format not in ['tab','csv']:
        print('Please ensure the data format of ancestry is either tab-delimited txt or csv')

    # Reads dataframe D with certain data format
    if D_file_format=='csv':
        D = pd.read_csv(D_file)
    else:
        D = pd.read_csv(D_file, sep='\t')

    # Reads dataframe ancestry with certain data format
    if ancestry_file_format=='csv':
        ancestry = pd.read_csv(ancestry_file)
    else:
        ancestry = pd.read_csv(ancestry_file, sep='\t')

    # Check the data format of dataframe D
    if abs(np.shape(np.shape(D))[0]-2)>0:
        print('Please ensure that data matrix D is size Nxk.')
        return

    # Check the format of obs
    if isinstance(obs,int)==False:
        print('Please ensure that obs is an integer.')
        return
    elif obs <=0:
        print('Please ensure that obs is a positive integer.')
        return

    # Check the data format of dataframe ancestry
    if abs(np.shape(np.shape(ancestry))[0]-2)>0:
        print('Please ensure that data matrix ancestry is size Nxk.')
        return

    # Check whether the column names in ancestry are in D
    for i in range(1, len(ancestry.columns)):
        if ancestry.columns[i] not in D.columns.values:
            print('Please ensure that the column names are same in D and ancestry')
            print('The first one with different column name is', end=' ')
            print(ancestry.columns[i], end=' ')
            print('in ancestry')
            return

    # Create the HA_check to find out whether there is a missing values in pi_hats and then we could use the Hidden
    # Ancestries Function to get those values
    HA_check = ancestry.isna()

    for i in range(1, len(ancestry.columns)):
        if HA_check.values[1, i]:
            answer_obj = HA(file=D_file, file_format=D_file_format, k=k, obs=obs, x_guess = x_guess)
            pi_final = answer_obj
            print(pi_final)
            # finish this part by inputting pi_hats from the result of HA function !!!!!!

    # Use HA_check to keep the columns names for that when using numpy to do computation will lose those column names
    HA_check = HA_check.drop(columns='pi')

    # Delete the useless columns on ancestry
    ancestry = ancestry.drop(columns='pi')


    # Grab the column names of references ancestries
    ref_ancestries = ancestry.columns.values[0:len(ancestry.columns)-1]

    # Grab the column name of single observation ancestry
    obs_ancestry = ancestry.columns.values[len(ancestry.columns)-1]

    # Transform ancestry from pandas dataframe into np array in order to compute
    ancestry = np.array(ancestry)

    # Make sure the sum of pi_hats and the sum of pi_stars are 1
    ancestry[0] = ancestry[0]/sum(ancestry[0])
    ancestry[1] = ancestry[1]/sum(ancestry[1])

    # Create hatted which uses for summing up reference ancestries multiplied by pi_star and initialize it with the
    # result of the first reference ancestry
    hatted = D[ref_ancestries[0]] * ancestry[1,0]

    # create hatted which uses for summing up reference ancestries multiplied by pi_hat and initialize it with the
    # result of the first reference ancestry
    starred = D[ref_ancestries[0]] * ancestry[0,0]

    # Add the missing column names on the ancestry
    ancestry = pd.DataFrame(ancestry, columns=HA_check.columns.values)

    # For those cases with more than one reference ancestries, sum the starred and hatted for other reference ancestries
    if len(ref_ancestries) > 1:
        for i in range(1, len(ref_ancestries)):
            hatted = hatted + D[ref_ancestries[i]] * ancestry.loc[1,ref_ancestries[i]]
            starred = starred + D[ref_ancestries[i]] * ancestry.loc[0,ref_ancestries[i]]

    updateAF = np.zeros((len(D),1))
    # Get the updated allele frequency
    for i in range(len(D)):
        updateAF[i] = ((ancestry.loc[0, obs_ancestry]/ancestry.loc[1, obs_ancestry]) * (D[obs_ancestry] - hatted)[[i]]
                    + starred[[i]])

    # Merge the updateAF into the original data
    updateAF = pd.DataFrame(data=updateAF, columns=['updateAF'])
    updateAF = pd.concat([D, updateAF], axis=1)

    # Stop the clock
    stop = timeit.default_timer()

    # Difference stop-start tells us run time
    time = stop - start

    print("The running time is", end=' ')
    print(time)

    return updateAF
