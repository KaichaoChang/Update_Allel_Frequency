# The Update Allele Frequencies Function

# The function should contain three inputs: a string D_file, a string D_file_format, the string ancestry_file, a
# string ancestry_file_format;
# The function will provide us an array: updateAF, the last column is the updateAF we got based on our SNPs, pi_hat
# and pi_star. Besides, the function also provide the overall runtime of the program.

# D_file: the file location of the Dataframe D, which should be in the same format as following;
#   CHR  RSID       BP       A1 A2  ref_eur_1000G ...  ref_iam_1000G   gnomAD_afr    gnomAD_amr    gnomAD_oth
#   1    rs2887286  1156131  C  T   0.173275495   ...  0.7093          0.4886100     0.52594300    0.22970500
#   1    rs41477744 2329564  A  G   0.001237745   ...  0.0000          0.0459137     0.00117925    0.00827206
#   1    rs9661525  2952840  G  T   0.168316089   ...  0.2442          0.1359770     0.28605200    0.15561700
#   1    rs2817174  3044181  C  T   0.428212624   ...  0.5000          0.8548790     0.48818000    0.47042500
#   1    rs12139206 3504073  T  C   0.204214851   ...  0.3372          0.7241780     0.29550800    0.25874800
#   1    rs7514979  3654595  T  C   0.004950604   ...  0.0000          0.3362490     0.01650940    0.02481620
# ...
# The dataframe D should contain the CHR, RSID, bP, A1, A2, the reference ancestries and observation ancestries, and
# the order of those columns should also be the same as the example one
# reference ancestries: ref_xxx_1000G (xxx represents the name abbreviation of the ancestries
# observation ancestries: gnomAD_xxx

# D_file_format: this function can deal with two different data input format, if the data format is tab-delimited text
# the we need to make the file_format as 'tab' to get the dataframe D from a file of such format, which is the common
# used data format when dealing with allel frequencies; if the user only gets the csv data, then the user should input
# file_format as csv. The default is 'tab'.

# ancestry_file: the file location of Dataframe ancestry. For this input, user needs to provide the pi_hat and pi_star
# value for the reference ancestries and observed ancestries they want to estimate. But if the user don't have a
# calculated pi_hat, the user could use the HA function to get those pi_hat they want. The function could be got by the
# link https://github.com/jordanrhall/Hidden_Ancestries/blob/master/HA_script.py.
# Here pi_hat represents the ancestry proportions the user inputs for the updated allele frequency.
# And pi_star represents the estimated genome-wide mixture proportions for all ancestries.
# Therefore, pi_star should be provided by the user, while the pi_star is better calculated by some algorithm, such as
# the HA function provided on the link.
# The user should provide both pi_hat and pi_star, and the input should be in the same format as following:
# pi       ref_eur_1000G  obs_afr_gnmoad
# pi_star  0              1
# pi_hat   0.15           0.85
# In this example, we only have one reference ancestry, which is ref_eur_1000G and we have one observed ancestry,
# which is gnomAD_afr.
# * One essential thing for the column name of the ancestry: the column names of the reference ancestries and
# observed ancestry should be exactly the same as the one in the dataframe D.

# ancestry_file_format: the data format of the input file of dataframe ancestry(the function of this input is exactly
# the same as the D_file_format. The default is also "tab".

# Then we get one output updateAF, which is the updated hidden proportions of every reference ancestry we select.

# Example:
# output = updateHA("D_file_location","D_file_format","ancestry_file_location","ancestry_file_format")

# The output of Example;
#The running time is 21.623375699999997
#   CHR  RSID       BP       A1 A2  ref_eur_1000G ...  ref_iam_1000G   gnomAD_afr    gnomAD_amr    gnomAD_oth   updateAF
#   1    rs2887286  1156131  C  T   0.173275495   ...  0.7093          0.4886100     0.52594300    0.22970500   0.544257
#   1    rs41477744 2329564  A  G   0.001237745   ...  0.0000          0.0459137     0.00117925    0.00827206   0.053798
#   1    rs9661525  2952840  G  T   0.168316089   ...  0.2442          0.1359770     0.28605200    0.15561700   0.130270
#   1    rs2817174  3044181  C  T   0.428212624   ...  0.5000          0.8548790     0.48818000    0.47042500   0.930173
#   1    rs12139206 3504073  T  C   0.204214851   ...  0.3372          0.7241780     0.29550800    0.25874800   0.815936
#   1    rs7514979  3654595  T  C   0.004950604   ...  0.0000          0.3362490     0.01650940    0.02481620   0.394713
# ...

# Here we get the updateAF we want and the run time, which is 21.623375699999997 seconds, where in the example we use
# 10000 rows of data.


# Here is the main code of the functionã€‚
import numpy as np
import pandas as pd
import timeit

np.set_printoptions(threshold=np.inf)


def updateHA(D_file=None, D_file_format='tab', ancestry_file=None, ancestry_file_format='tab'):
    # Start the clock
    start = timeit.default_timer()

    # Check the input formt of D_file_format
    if D_file_format not in ['tab','csv']:
        print('Please ensure the data format of D is either tab-delimited txt or csv')
        return

    # Check the input formt of ancestry_file_format
    if ancestry_file_format not in ['tab','csv']:
        print('Please ensure the data format of ancestry is either tab-delimited txt or csv')
        return

    # Reads dataframe D with certain data format
    if D_file_format=='csv':
        D = pd.read_csv(D_file)
    else:
        D = pd.read_csv(D_file, sep='\t')

    # Reads dataframe ancestry with certain data format
    if ancestry_file_format=='csv':
        ancestry = pd.read_csv(ancestry_file)
    else:
        ancestry = pd.read_csv(ancestry_file, sep='\t')

    # Check the data format of dataframe D
    if abs(np.shape(np.shape(D))[0]-2)>0:
        print('Please ensure that data matrix D is size Nxk.')
        return

    # Check the data format of dataframe ancestry
    if abs(np.shape(np.shape(ancestry))[0]-2)>0:
        print('Please ensure that data matrix ancestry is size Nxk.')
        return

    # Check whether the column names in ancestry are in D
    for i in range(1, len(ancestry.columns)):
        if ancestry.columns[i] not in D.columns.values:
            print('Please ensure that the column names are same in D and ancestry')
            print('The first one with different column name is', end=' ')
            print(ancestry.columns[i], end=' ')
            print('in ancestry')
            return

    # Create the HA_check to find out whether there is a missing values in pi_hats and then we could use the Hidden
    # Ancestries Function to get those values
    HA_check = ancestry.isna()

    for i in range(1, len(ancestry.columns)):
        if HA_check.values[0, i]:
            print("Please provide all pi_star, in order to run the function.")
            return

    for i in range(1, len(ancestry.columns)):
        if HA_check.values[1, i]:
            print("Please provide all pi_hat, in order to run the function.")
            return

    # Use HA_check to keep the columns names for that when using numpy to do computation will lose those column names
    HA_check = HA_check.drop(columns='pi')

    # Delete the useless columns on ancestry
    ancestry = ancestry.drop(columns='pi')


    # Grab the column names of references ancestries
    ref_ancestries = ancestry.columns.values[0:len(ancestry.columns)-1]

    # Grab the column name of single observation ancestry
    obs_ancestry = ancestry.columns.values[len(ancestry.columns)-1]

    # Transform ancestry from pandas dataframe into np array in order to compute
    ancestry = np.array(ancestry)

    # Make sure the sum of pi_hats and the sum of pi_stars are 1
    ancestry[0] = ancestry[0]/sum(ancestry[0])
    ancestry[1] = ancestry[1]/sum(ancestry[1])

    # Create hatted which uses for summing up reference ancestries multiplied by pi_star and initialize it with the
    # result of the first reference ancestry
    hatted = D[ref_ancestries[0]] * ancestry[1,0]

    # create hatted which uses for summing up reference ancestries multiplied by pi_hat and initialize it with the
    # result of the first reference ancestry
    starred = D[ref_ancestries[0]] * ancestry[0,0]

    # Add the missing column names on the ancestry
    ancestry = pd.DataFrame(ancestry, columns=HA_check.columns.values)

    # For those cases with more than one reference ancestries, sum the starred and hatted for other reference ancestries
    if len(ref_ancestries) > 1:
        for i in range(1, len(ref_ancestries)):
            hatted = hatted + D[ref_ancestries[i]] * ancestry.loc[1,ref_ancestries[i]]
            starred = starred + D[ref_ancestries[i]] * ancestry.loc[0,ref_ancestries[i]]

    updateAF = np.zeros((len(D),1))
    # Get the updated allele frequency
    for i in range(len(D)):
        updateAF[i] = ((ancestry.loc[0, obs_ancestry]/ancestry.loc[1, obs_ancestry]) * (D[obs_ancestry] - hatted)[[i]]
                    + starred[[i]])

    # Merge the updateAF into the original data
    updateAF = pd.DataFrame(data=updateAF, columns=['updateAF'])
    updateAF = pd.concat([D, updateAF], axis=1)

    # Stop the clock
    stop = timeit.default_timer()

    # Difference stop-start tells us run time
    time = stop - start

    print("The running time is", end=' ')
    print(time)

    return updateAF
